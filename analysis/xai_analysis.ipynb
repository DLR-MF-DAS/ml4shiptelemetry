{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of model explainability using SHAP\n",
    "\n",
    "This notebook contains code to analyze the predictions of the ML4ShipTelemetry models. [SHAP](https://github.com/shap/shap/tree/master) is used for explaining the impact of the input features on the model output.\n",
    "\n",
    "Both quality flag classification and the regression models are analyzed.\n",
    "\n",
    "The primary goal is to identify which features plays the strongest role in the models, and to gauge whether the models have overfitted to unexpected features or use reasonable features according to domain experts.\n",
    "\n",
    "\n",
    "\n",
    "As a bonus, we create interactive maps of the data using [KeplerGL](https://kepler.gl/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some display options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to stored models and data\n",
    "\n",
    "# Base path to ml4shiptelemetry package: */ml4shiptelemetry/\n",
    "base_path = '/path/to/ml4shiptelemetry/'\n",
    "\n",
    "# Path (relative or absolute) to the data file (.npz file format) created by running main().\n",
    "data_dir = os.path.join(base_path, 'data', 'proc_files_n_test_files_3_n_neighbours_0.npz')\n",
    "\n",
    "# Path (relative or absolute) to the file containing the trained regression models (.pkl file format) created by running main().\n",
    "model_reg_path = os.path.join(base_path, 'output', 'model_regression_n_neighbours_0.pkl')\n",
    "\n",
    "# Path (relative or absolute) to the file containing the trained classification models (.pkl file format) created by running main().\n",
    "model_path = os.path.join(base_path, 'output', 'model_classification_n_neighbours_0.pkl')\n",
    "\n",
    "# Path to folder where SHAP files should be written to and read from, e.g. one folder above ml4shiptelemetry.\n",
    "shap_path = '/path/to/shap_folder/'\n",
    "\n",
    "# Configure export settings\n",
    "export_figs = True\n",
    "export_figs_format = '.png'\n",
    "\n",
    "# Create rng for deterministic sampling\n",
    "rng = np.random.default_rng(1011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and models\n",
    "\n",
    "Load data and models and perform some simple postprocessing to classify the predictions into true positives, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.load(data_dir)\n",
    "x = data['x']\n",
    "y_reg = data['y_reg']\n",
    "y_class = data['y_class']\n",
    "x_test = data['x_test']\n",
    "y_test_reg = data['y_test_reg']\n",
    "y_test_class = data['y_test_class']\n",
    "targets_reg = data['targets_reg']\n",
    "targets_class = data['targets_class']\n",
    "feature_names = data['feature_names'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training and test data\n",
    "df_train = pd.DataFrame(data=x, columns=feature_names)\n",
    "df_train[targets_class.tolist()] = y_class\n",
    "df_train[targets_reg.tolist()] = y_reg\n",
    "\n",
    "df_test = pd.DataFrame(data=x_test, columns=feature_names)\n",
    "df_test[targets_class.tolist()] = y_test_class\n",
    "df_test[targets_reg.tolist()] = y_test_reg\n",
    "\n",
    "df_train['train'] = True\n",
    "df_test['train'] = False\n",
    "\n",
    "# Combined training and test data to single dataframe\n",
    "dff = pd.concat([df_train, df_test], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "models = joblib.load(model_path)\n",
    "model_temp = models['Temp_Flag']['classifier'].classifier\n",
    "model_sal = models['Sal_Flag']['classifier'].classifier\n",
    "model_reg = joblib.load(model_reg_path).regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional performance metrics for classification models\n",
    "temp_ind = targets_class.tolist().index('Temp_Flag')\n",
    "sal_ind = targets_class.tolist().index('Sal_Flag')\n",
    "\n",
    "df_dict = {}\n",
    "for flag in ['Temp_Flag', 'Sal_Flag']:\n",
    "    if flag == 'Temp_Flag':\n",
    "        model = model_temp\n",
    "        ind = temp_ind\n",
    "    else:\n",
    "        model = model_sal\n",
    "        ind = sal_ind\n",
    "        \n",
    "    # True label\n",
    "    y_class = y_test_class[:, ind]\n",
    "    \n",
    "    \n",
    "    # Predicted label\n",
    "    y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Classify predictions into true positives, false, positives, ...\n",
    "    tp = (y_pred == 1) & (y_pred == y_class)\n",
    "    fp = (y_pred == 0) & (y_pred != y_class)\n",
    "    fn = (y_pred == 1) & (y_pred != y_class)\n",
    "    tn = (y_pred == 0) & (y_pred == y_class)\n",
    "\n",
    "    # Calcualte difference in probability of the classification output.\n",
    "    prob_diff = np.abs(y_class - y_pred_proba)\n",
    "\n",
    "    # Build dataframe with test data as well as the prediction metrics\n",
    "    dfe = pd.DataFrame(data=x_test, columns=feature_names)\n",
    "    dfe['true_class'] = y_class\n",
    "    dfe['pred'] = y_pred\n",
    "    dfe['prob'] = y_pred_proba\n",
    "    dfe['prob_diff'] = prob_diff\n",
    "    dfe['tp'] = tp\n",
    "    dfe['fp'] = fp\n",
    "    dfe['fn'] = fn\n",
    "    dfe['tn'] = tn\n",
    "    dfe['pred_type'] = (1*dfe['fp'] + 2*dfe['tp'] - 1*dfe['fn'] - 2*dfe['tn']).astype(int)\n",
    "    df_dict[flag] = dfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create KeplerGL map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Create KeplerGl map\n",
    "create_kepler_map = False\n",
    "\n",
    "if create_kepler_map:\n",
    "    from keplergl import KeplerGl\n",
    "    map1 = KeplerGl(data={'df': dff[['train', 'SYS.STR.PosLat','SYS.STR.PosLon']+targets_class.tolist()+targets_reg.tolist()].rename(columns={'SYS.STR.PosLat':'latitude','SYS.STR.PosLon':'longitude'})})\n",
    "    map1.save_to_html(file_name=os.path.join(base_path, 'imgs', 'map_of_data_positions.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing SHAP calculations if they exist, otherwise recalculate them\n",
    "# Temp. classification shap model\n",
    "try:\n",
    "    expl_temp = joblib.load(os.path.join(shap_path, 'explainer_temp.pkl'))\n",
    "except:    \n",
    "    expl_temp = shap.TreeExplainer(model_temp, feature_names=feature_names)\n",
    "    joblib.dump(expl_temp, os.path.join(shap_path, 'explainer_temp.pkl'))\n",
    "\n",
    "# Sal. classification shap model\n",
    "try:\n",
    "    expl_sal = joblib.load(os.path.join(shap_path, 'explainer_sal.pkl'))\n",
    "except:    \n",
    "    expl_sal = shap.TreeExplainer(model_sal, feature_names=feature_names)\n",
    "    joblib.dump(expl_sal, os.path.join(shap_path, 'explainer_sal.pkl'))\n",
    "\n",
    "# Regression classification shap model\n",
    "try:\n",
    "    expl_reg = joblib.load('explainer_reg.pkl')\n",
    "except:\n",
    "    expl_reg = shap.TreeExplainer(model_reg, feature_names=feature_names)\n",
    "    joblib.dump(expl_reg, os.path.join(shap_path, 'explainer_reg.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample random test samples for SHAP plots, equally many from positive and negative class.\n",
    "\n",
    "shap_dict = {}\n",
    "# Temperature\n",
    "x_test_temp_neg = x_test[y_test_class[:, temp_ind]==0, :]\n",
    "\n",
    "# Sample positive values from this range\n",
    "# All negative samples have latitude < 40\n",
    "# Randomly sample equally many positive samples as negative\n",
    "n_negative = x_test_temp_neg.shape[0]\n",
    "pos_ind = y_test_class[:,temp_ind]==1\n",
    "x_test_temp_pos = x_test[pos_ind, :][rng.choice(pos_ind.sum(), size=n_negative), :]\n",
    "shap_dict['Temp_Flag'] = {'pos': x_test_temp_pos, 'neg': x_test_temp_neg}\n",
    "\n",
    "# Salinity\n",
    "x_test_sal_neg = x_test[y_test_class[:,sal_ind]==0, :]\n",
    "\n",
    "# Sample positive values from this range\n",
    "# All negative samples have latitude < 40\n",
    "# Randomly sample equally many positive samples as negative\n",
    "n_negative = x_test_sal_neg.shape[0]\n",
    "pos_ind = y_test_class[:,sal_ind]==1\n",
    "x_test_sal_pos = x_test[pos_ind, :][rng.choice(pos_ind.sum(), size=n_negative), :]\n",
    "shap_dict['Sal_Flag'] = {'pos': x_test_sal_pos, 'neg': x_test_sal_neg}\n",
    "\n",
    "# Sample points from the regression data\n",
    "# Randomly sample\n",
    "n_sample = 10000\n",
    "x_test_reg = x_test[rng.choice(len(x_test), size=n_sample), :]\n",
    "shap_dict['reg'] = x_test_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values\n",
    "\n",
    "# Temperature flags\n",
    "# Negative samples\n",
    "try:\n",
    "    shap_values_temp_neg = joblib.load(os.path.join(shap_path, 'shap_values_temp_neg.pkl'))\n",
    "except:    \n",
    "    shap_values_temp_neg = expl_temp(shap_dict['Temp_Flag']['neg'])\n",
    "    joblib.dump(shap_values_temp_neg, os.path.join(shap_path, 'shap_values_temp_neg.pkl'))\n",
    "# Positive samples\n",
    "try:\n",
    "    shap_values_temp_pos = joblib.load(os.path.join(shap_path, 'shap_values_temp_pos.pkl'))\n",
    "except:    \n",
    "    shap_values_temp_pos = expl_temp(shap_dict['Temp_Flag']['pos'])\n",
    "    joblib.dump(shap_values_temp_pos, os.path.join(shap_path, 'shap_values_temp_pos.pkl'))\n",
    "\n",
    "# Salinty flags\n",
    "# Negative samples\n",
    "try:\n",
    "    shap_values_sal_neg = joblib.load(os.path.join(shap_path, 'shap_values_sal_neg.pkl'))\n",
    "except:    \n",
    "    shap_values_sal_neg = expl_sal(shap_dict['Sal_Flag']['neg'])\n",
    "    joblib.dump(shap_values_sal_neg, os.path.join(shap_path, 'shap_values_sal_neg.pkl'))\n",
    "# Positive samples\n",
    "try:\n",
    "    shap_values_sal_pos = joblib.load(os.path.join(shap_path, 'shap_values_sal_pos.pkl'))\n",
    "except:    \n",
    "    shap_values_sal_pos = expl_sal(shap_dict['Sal_Flag']['pos'])\n",
    "    joblib.dump(shap_values_sal_pos, os.path.join(shap_path, 'shap_values_sal_pos.pkl'))\n",
    "\n",
    "# Regression\n",
    "try:\n",
    "    shap_values_reg = joblib.load(os.path.join(shap_path, 'shap_values_reg.pkl'))\n",
    "except:    \n",
    "    shap_values_reg = expl_reg(shap_dict['reg'])\n",
    "    joblib.dump(shap_values_reg, os.path.join(shap_path, 'shap_values_reg.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_map = {'Temp [°C]':'temp', 'Cond [S/m]':'cond', 'Temp_int [°C]':'temp_int', 'Sal':'sal'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature\n",
    "\n",
    "Create SHAP value plots for temperature classfication of quality flags, showing the most important features, in terms of contribution to the prediction outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine SHAP values from negative and positive classes: Extract SHAP values, base values and data\n",
    "comb_vals = np.concatenate([shap_values_temp_neg.values, shap_values_temp_pos.values], axis=0)\n",
    "comb_base_vals = np.concatenate([shap_values_temp_neg.base_values, shap_values_temp_pos.base_values], axis=0)\n",
    "comb_data = np.concatenate([shap_values_temp_neg.data, shap_values_temp_pos.data], axis=0)\n",
    "# Create SHAP Explanation from the extracted information\n",
    "expl_temp = shap.Explanation(values=comb_vals, base_values=comb_base_vals, data=comb_data, feature_names=feature_names)\n",
    "\n",
    "# Plot feature importance\n",
    "fig = plt.figure()\n",
    "ax = shap.plots.beeswarm(expl_temp[:, :, 1], show=False)\n",
    "ax.set_title('Temperature flag')\n",
    "if export_figs:\n",
    "    fig.savefig(os.path.join(base_path, 'imgs', 'shap_temp_flag'+export_figs_format), bbox_inches='tight', transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance for only the negative class (\"bad\" flags)\n",
    "fig = plt.figure()\n",
    "ax = shap.plots.beeswarm(shap_values_temp_neg[:, :, 1], show=False)\n",
    "ax.set_title('Temperature, bad flags')\n",
    "if export_figs:\n",
    "    fig.savefig(os.path.join(base_path, 'imgs', 'shap_temp_flag_bad'+export_figs_format), bbox_inches='tight', transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flow in the mid range increase likelihood of predicting positive class (good flag). Low or high flow pushed toward negative class (bad flag)\n",
    "- High month of year push toward positive class (good flag). However, since we only have bad flags in jan, nov and dec is it likely not month related. The ship moves approx in -20 to 20 latitude, so all the time around the equator. Therefore, it is likely more due to sampling than the month itself. Likely we have bad flags toward the end of the measurement sequence\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance for only the positive class (\"good\" flags)\n",
    "fig = plt.figure()\n",
    "ax = shap.plots.beeswarm(shap_values_temp_pos[:, :, 1], show=False)\n",
    "ax.set_title('Temperature, good flags')\n",
    "if export_figs:\n",
    "    fig.savefig(os.path.join(base_path, 'imgs', 'shap_temp_flag_good'+export_figs_format), bbox_inches='tight', transparent=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salinity\n",
    "\n",
    "Create SHAP value plots for salinity classfication of quality flags, showing the most important features, in terms of contribution to the prediction outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine SHAP values from negative and positive classes: Extract SHAP values, base values and data\n",
    "comb_vals = np.concatenate([shap_values_sal_neg.values, shap_values_sal_pos.values], axis=0)\n",
    "comb_base_vals = np.concatenate([shap_values_sal_neg.base_values, shap_values_sal_pos.base_values], axis=0)\n",
    "comb_data = np.concatenate([shap_values_sal_neg.data, shap_values_sal_pos.data], axis=0)\n",
    "# Create SHAP Explanation from the extracted information\n",
    "expl_sal = shap.Explanation(values=comb_vals, base_values=comb_base_vals, data=comb_data, feature_names=feature_names)\n",
    "\n",
    "# Plot feature importance\n",
    "fig = plt.figure()\n",
    "ax = shap.plots.beeswarm(expl_sal[:, :, 1], show=False)\n",
    "ax.set_title('Salinity flag')\n",
    "if export_figs:\n",
    "    fig.savefig(os.path.join(base_path, 'imgs', 'shap_sal_flag'+export_figs_format), bbox_inches='tight', transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance for only the negative class (\"bad\" flags)\n",
    "fig = plt.figure()\n",
    "ax = shap.plots.beeswarm(shap_values_sal_neg[:, :, 1], show=False)\n",
    "ax.set_title('Salinity, bad flags')\n",
    "if export_figs:\n",
    "    fig.savefig(os.path.join(base_path, 'imgs', 'shap_sal_flag_bad'+export_figs_format), bbox_inches='tight', transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance for only the positive class (\"good\" flags)\n",
    "fig = plt.figure()\n",
    "ax = shap.plots.beeswarm(shap_values_sal_pos[:, :, 1], show=False)\n",
    "ax.set_title('Salinity, good flags')\n",
    "if export_figs:\n",
    "    fig.savefig(os.path.join(base_path, 'imgs', 'shap_sal_flag_good'+export_figs_format), bbox_inches='tight', transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance for the regression model on the four targets\n",
    "for ind, t in enumerate(targets_reg):\n",
    "    fig = plt.figure()\n",
    "    ax = shap.plots.beeswarm(shap_values_reg[:, :, ind], show=False)\n",
    "    ax.set_title(t)\n",
    "    if export_figs:\n",
    "        fig.savefig(os.path.join(base_path, 'imgs', f'shap_{file_name_map[t]}'+export_figs_format), bbox_inches='tight', transparent=False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geomar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
